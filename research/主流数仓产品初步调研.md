# 数仓落地调研step1

## 现有的企业数仓方案

### 概述

传统数仓思路为通过分层设计为bi（推荐，机器学习等）应用查询分担压力，复杂和join计算提前进行，统一在ETL和入数据集市时处理掉（join，连接等运算）生成大宽表。汇总计算交给OLAP计算引擎进行。

### hive 数仓

hive是基于hadoop的一个数据仓库工具。可以将存储在HDFS文件系统之上的结构化数据映射成一张数据表（hive提供元数据管理服务）。向上提供完整的sql查询查询功能，内在原理是将sql语句转化为MR任务。

优点：基于HDFS系统，扩展性极高，业界验证dataNode可以扩展到成千上万个节点；类sql查询接口；

缺点：MR任务性能较慢；存储和计算不分离；HDFS组件很多，安装比较笨重；适用于离线计算，数仓实时性较差；

### spark、presto 、Impala 等计算引擎 on HDFS数仓

优点：可以构建存储和计算分离的架构；速度也相对较快（内存计算，解析sql的依赖关系成DAG图，无依赖关系全部并行）；

缺点：依赖于HDFS系统，部署复杂，cloud-native下需要部署HDFS（尽管现在HDFS系统支持对象存储作为底层存储，但是还是绕了一圈）；

### clickhouse数仓

优点：计算引擎性能快，部署方便

缺点：存储和计算不分离；扩容涉及到数据的迁移；replica高度依赖zk的可用性；mergetree引擎家族特点明显；

### snowflake、google bigquery、阿里的ADB、Maxcompute云数仓

优点：完全在公有云上建设。对于中小企业、公有云信任和业务数据本身就在公有云上的客户吸引力大（不用自己部署应用，只需要数据接入即可）；sql使用方便，建表不用指定引擎，计算节点弹性管理；提供数据加密服务；其中我认为snowflake真正实现了daas功能（数据即服务），且使用成本是最小的（存储基于对象存储，算力会在停止工作期间释放），运维完全交给公有云；

缺点：国内企业特别是国企，银行客户不会将数据上传到云端；不允许访问外网；

*注：目前没有发现腾讯云上类似的云数仓的saas服务，只有基于开源的clickhouse和postgresql数据仓库/数据湖托管服务*

## 未来数仓的趋势

### s3 存储的优势

+ 简单，s3为“simple storage service”的简写，key value形式存储
+ 无限扩容
+ 高可用，公有云上11个9的可靠性，基于minio的本地搭建的s3对象存储也是具有n/2个节点的故障容忍度
+ 成本低（以腾讯云价格为例）
  + 标准存储容量包：1T一年900元
  + 低频存储容量包：1T一年600元
  + 归档存储容量包：1T一年255元

对象存储已成为云化存储的基础设施。

### 存储和计算分离的优势

+ 便宜的存储
+ 更高的带宽
+ 计算节点无状态，运维方便
+ 成本控制
+ 云化

这些技术的发展会催生所有数据库结构往计算和存储分离的方向去设计，不仅仅是olap分析行数据库

### snowflake的启示

snowflake有三层：

+ 存储层，基于对象存储（便宜）
+ 弹性计算层vm：可真正动态调整；根据使用情况动态启动、停止
+ 服务层：其他需要常驻、多租户管理、权限、调度等共享服务

关键点：

+ 极致的追求减低总成本 （并让客户能理解），
+ 相比于谷歌的bigquery，把计费模式更透明更让客户容易理解 （而不是API调用次数）

## 落地的建议

两种方案：

+ 直接在公有云的基础上构建saas（或者叫daas服务）---- snowflake模式

  需要做的事情：

  ---  需要一个计算分离的、支持云存储的数仓在公有云上的部署；
  ---  需要一个web服务，功能：管理租户权限、数据上传、数据查询页面、监控页面、直接对接客户云上的数据进行入仓；

+ 为客户提供数仓解决方案：其特点为：

  海量数据存储、弹性伸缩，私有化部署，好用，性能不差

其中方案一实现难度更大，比较现实的路线是先采用第二种方案，技术实现要cloud-native。并在第二种方案能够顺利实施成熟时，开始构建云上的服务。

技术落地方向：

存储系统和计算系统解耦：计算引擎和存储引擎可以分别研发；

需要一个web服务，功能：租户管理、SQL查询、监控页面、各种数据接入；

基于对象存储构建，选取高性能计算引擎；（私有云部署可以使用minio在文件系统上构建s3对象存储服务）

对象存储的表结构形式建模（元数据管理）；

是否需要提供time travel功能？

### clickhouse 存储与计算分离可行性分析

mergeTree引擎已支持对象存储，需要做的主要是计算引擎的无状态处理（计算引擎元数据共享，需要一个协调节点与元数据公共存储的地方）

优点：计算引擎性能快；社区也在推进这件事

缺点：直接对接s3存储，time -travel 功能需要单独开发；

### 需要继续调研的方案

presto/spark on apache iceberg（本地存储用minio构建对象存储）

优点：全部开源且质量高；目前调研的情况看，可以实现存储和计算分离；针对s3对象存储；性能调研还可以

所以下一步计划实操一下这个方案，体验一下部署的复杂性和功能，有必要再测试一下性能。







## 一站数据湖分析平台

+ 最底下是分布式文件系统，云上用户 S3 和 oss 这种对象存储会用的更多一些，毕竟价格便宜很多；非云上用户一般采用自己维护的 HDFS。

+ 第二层是数据加速层。数据湖架构是一个存储计算彻底分离的架构，如果所有的数据访问都远程读取文件系统上的数据，那么性能和成本开销都很大。如果能把经常访问到的一些热点数据缓存在计算节点本地，这就非常自然的实现了冷热分离，一方面能收获到不错的本地读取性能，另一方面还节省了远程访问的带宽。这一层里面，我们一般会选择开源的 alluxio，或者选择阿里云上的 Jindofs。

+ 第三层就是 Table format 层，主要是把一批数据文件封装成一个有业务意义的 table，提供 ACID、snapshot、schema、partition 等表级别的语义。一般对应这开源的 Delta、Iceberg、Hudi 等项目。对一些用户来说，他们认为Delta、Iceberg、Hudi 这些就是数据湖，其实这几个项目只是数据湖这个架构里面的一环，只是因为它们离用户最近，屏蔽了底层的很多细节，所以才会造成这样的理解。

+ 最上层就是不同计算场景的计算引擎了。开源的一般有 Spark、Flink、Hive、Presto、Hive MR 等，这一批计算引擎是可以同时访问同一张数据湖的表的。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy84QXNZQmljRWVQdTZwMlNrN2hrU0NFaWJQYmE5Y1RubG1RM2JWSWlhM2liUERUQ1pnelp4SmljcHR0eUI2cURzamlhOGxzU25HblVtUndFWFBXY2JseWZ1dTBXQS82NDA?x-oss-process=image/format,png)

![what-is-2](https://github.com/kafka1991/lakehouseResearch/blob/master/picture/what-is-2.png)

![engine-3](https://github.com/kafka1991/lakehouseResearch/blob/master/picture/engine-3.png)

